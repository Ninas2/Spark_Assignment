{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "434c5c0b-da06-4238-8858-52f7c0be6bb0",
   "metadata": {},
   "source": [
    "# Big Data Systems Architecture - Spark Assignment "
   ]
  },
  {
   "cell_type": "raw",
   "id": "f81ca8c6-6c10-443f-bf03-ea8ff327573b",
   "metadata": {},
   "source": [
    "Konstantinos Ninas, f2822108\n",
    "MSc in Business Analytics\n",
    "Department of Management Science and Technology\n",
    "Athens University of Economics and Business \n",
    "f2822108@aueb.gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "bce38d29-734b-40d8-97b6-bff2a9cd0c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import of libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "1988298c-dca2-4422-9d30-3519770c6979",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We create a spark session in order to create an application to exlore the data\n",
    "spark = SparkSession.builder.appName(\"Linear_Regression\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "f2b98d7e-8f59-41fa-9574-a8564cebdbee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We load the dataset in a dataframe. We read the file with the .json() function\n",
    "books = spark.read.json(\"books_5000.json\")\n",
    "type(books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "9e9dcc33-095f-4fe8-8fd3-ab2b33548592",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we fill the empty string values of the language_code and publication_year values with 'None'.\n",
    "books = books.withColumn('language_code', when(col('language_code') == '', 'None').otherwise(col('language_code')))\n",
    "books = books.withColumn('publication_year', when(col('publication_year') == '', 'None').otherwise(col('publication_year')))\n",
    "\n",
    "#We convert the data types of the num_pages, ratings_count and average_rating variables from string to numeric (integer and float)\n",
    "books = books.withColumn(\"num_pages\",col(\"num_pages\").cast(\"integer\"))\n",
    "books = books.withColumn(\"ratings_count\",col(\"ratings_count\").cast(\"integer\"))\n",
    "books = books.withColumn(\"average_rating\",col(\"average_rating\").cast(\"float\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "ab3ecfe0-678d-4aeb-8324-54ea0b2e22b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we fill the null (or na) values of the numeric variables with 0\n",
    "books = books.na.fill(0,(\"num_pages\", \"ratings_count\", \"average_rating\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "c7de9570-9732-4bf6-9de0-df48414a4421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3505\n",
      "1494\n"
     ]
    }
   ],
   "source": [
    "#We split the dataset in train and test\n",
    "trainDF, testDF = books.randomSplit([0.7, 0.3], seed=15)\n",
    "\n",
    "print(trainDF.cache().count()) # Cache because accessing training data multiple times\n",
    "\n",
    "print(testDF.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "0e7d72da-ec6f-41f6-88de-5305cd2397f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We determine which of the columns are categorical.\n",
    "categorical_cols = ['language_code', 'publication_year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "f9edde62-caeb-4eee-b0d9-54c414f4e296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following two lines are estimators. They return functions that we will later apply to transform the dataset.\n",
    "stringIndexer = StringIndexer(inputCols=categorical_cols, outputCols=[x + \"Index\" for x in categorical_cols]).setHandleInvalid('keep')\n",
    "encoder = OneHotEncoder(inputCols=stringIndexer.getOutputCols(), outputCols=[x + \"OHE\" for x in categorical_cols]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "47f348b3-ee4c-4dcf-b736-82a4f2e8de73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+--------------+--------+------------+--------------------+-------------------+---------+--------------------+--------+----------+-------------+-----------+-------------+--------------------+---------+--------------------+---------------+-----------------+----------------+--------------------+-------------+--------------------+--------------------+------------------+--------------------+--------------------+--------------------+--------+------------------+---------------------+\n",
      "|      asin|             authors|average_rating| book_id|country_code|         description|edition_information|   format|           image_url|is_ebook|      isbn|       isbn13|kindle_asin|language_code|                link|num_pages|     popular_shelves|publication_day|publication_month|publication_year|           publisher|ratings_count|              series|       similar_books|text_reviews_count|               title|title_without_series|                 url| work_id|language_codeIndex|publication_yearIndex|\n",
      "+----------+--------------------+--------------+--------+------------+--------------------+-------------------+---------+--------------------+--------+----------+-------------+-----------+-------------+--------------------+---------+--------------------+---------------+-----------------+----------------+--------------------+-------------+--------------------+--------------------+------------------+--------------------+--------------------+--------------------+--------+------------------+---------------------+\n",
      "|B00NLXQ534|       [{8551671, }]|          4.12|25742454|          US|Lillian Ann Cross...|                   |         |https://s.gr-asse...|    true|          |             |           |         None|https://www.goodr...|        0|[{228, to-read}, ...|               |                 |            None|                    |            1|                  []|[25653153, 256991...|                 1|The Switchblade M...|The Switchblade M...|https://www.goodr...|42749946|               0.0|                  0.0|\n",
      "|          |       [{3274315, }]|          3.94|30128855|          US|Florence Dupre La...|                   |         |https://images.gr...|   false|2205073346|             |           |          fre|https://www.goodr...|        0|[{2, bd}, {2, to-...|             22|                1|            2016|             Dargaud|           16|                  []|                  []|                 2|             Cruelle|             Cruelle|https://www.goodr...|50558228|               3.0|                  2.0|\n",
      "|          |         [{37450, }]|          4.28|13571772|          US|The questions pla...|                   |Hardcover|https://images.gr...|   false|          |             |           |          eng|https://www.goodr...|      146|[{493, to-read}, ...|               |                 |            2012|Hachette Partwork...|           51|[246830, 362583, ...|[13590139, 105963...|                 5|Captain America: ...|Captain America: ...|https://www.goodr...|  102217|               1.0|                  5.0|\n",
      "|B06XKGGSB7|[{16209952, }, {8...|          4.05|35452242|          US|The fight for Jas...|                   |         |https://s.gr-asse...|    true|          |             | B06XKGGSB7|          eng|https://www.goodr...|        0|[{222, to-read}, ...|               |                 |            None|                    |            6|                  []|                  []|                 1|Bounty Hunter 4/3...|Bounty Hunter 4/3...|https://www.goodr...|54276229|               1.0|                  0.0|\n",
      "|          |[{81563, }, {8953...|          4.06|  707611|          US|These are the sto...|                   |Hardcover|https://images.gr...|   false|0930289765|9780930289768|           |        en-US|https://www.goodr...|      272|[{20, to-read}, {...|             14|               11|            1997|           DC Comics|           51|   [266759, 1096220]|                  []|                 6|Superman Archives...|Superman Archives...|https://www.goodr...|  693886|               6.0|                 20.0|\n",
      "+----------+--------------------+--------------+--------+------------+--------------------+-------------------+---------+--------------------+--------+----------+-------------+-----------+-------------+--------------------+---------+--------------------+---------------+-----------------+----------------+--------------------+-------------+--------------------+--------------------+------------------+--------------------+--------------------+--------------------+--------+------------------+---------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stringIndexerModel = stringIndexer.fit(books)\n",
    "stringIndexerModel.transform(books).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "0ee742c7-f2c2-41d5-aee2-f4b59abc875a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This includes both the numeric columns and the one-hot encoded binary vector columns in our dataset.\n",
    "numericCols = [\"num_pages\",\"ratings_count\"]\n",
    "assemblerInputs = [c + \"OHE\" for c in categorical_cols] + numericCols\n",
    "vecAssembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "ba6142cd-8447-43ff-bc6f-bf1095cf1988",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "#we fit a linear regression model\n",
    "LinReg = LinearRegression(featuresCol=\"features\", labelCol ='average_rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "86da68b1-f2dd-4674-8347-8b29bc866cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Define the pipeline based on the stages created in previous steps.\n",
    "pipeline = Pipeline(stages=[stringIndexer, encoder, vecAssembler, LinReg])\n",
    "\n",
    "# Define the pipeline model.\n",
    "pipelineModel = pipeline.fit(trainDF)\n",
    "\n",
    "# Apply the pipeline model to the test dataset to classify the respective samples.\n",
    "predDF = pipelineModel.transform(testDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "d17cd8e9-8fbd-4f09-be8b-3e5c59bdbdf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-Squared value of the Linear Regression Model is: 0.03716860928892651\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "evaluator = RegressionEvaluator(metricName=\"r2\")\n",
    "evaluator.setLabelCol(\"average_rating\")\n",
    "print(f\"R-Squared value of the Linear Regression Model is: {evaluator.evaluate(predDF)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
