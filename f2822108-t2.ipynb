{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "408e96d3-fa06-4aa6-98a8-75af1e06621d",
   "metadata": {},
   "source": [
    "# Big Data Systems Architecture - Spark Assignment "
   ]
  },
  {
   "cell_type": "raw",
   "id": "6746668c-4473-4175-8d76-4e049ba872c0",
   "metadata": {},
   "source": [
    "Konstantinos Ninas, f2822108\n",
    "MSc in Business Analytics\n",
    "Department of Management Science and Technology\n",
    "Athens University of Economics and Business \n",
    "f2822108@aueb.gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "218a7fd9-790f-4026-afef-4bdb9174bb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import of libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "06582568-2202-43a4-9e9d-059ca39e0128",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We create a spark session in order to create an application to exlore the data\n",
    "spark = SparkSession.builder.appName(\"SQL_Queries\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "09a06fef-a7c0-4936-8c7c-cf89ae78d9a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We load the dataset in a dataframe. We read the file with the .json() function\n",
    "new_books = spark.read.json(\"books_5000.json\")\n",
    "type(new_books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "8975d077-7d26-4603-8eac-7a288ff8185a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We create a global view of the new_books dataframe, so it can be accessed from any application in different sessions\n",
    "new_books.createOrReplaceTempView(\"test_books\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "70224a33-b58d-496e-9dae-63edddd27894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------+\n",
      "| book_id|               title|average_rating|\n",
      "+--------+--------------------+--------------+\n",
      "|27217506|Not a Villain, vo...|          4.75|\n",
      "+--------+--------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#We use a nested select to find all the movies that start with 'N' and sort them in descending order based on their average rating. Then, on the outer loop we select the first \n",
    "#record using the limit command \n",
    "best_N_book = spark.sql(\"SELECT book_id, title, average_rating FROM ( \\\n",
    "          SELECT book_id, title, average_rating FROM test_books WHERE (title like 'N%' OR title like 'n%') ORDER BY average_rating DESC) LIMIT 1\")\n",
    "best_N_book.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "b345d9db-ba55-487a-94ea-8ddddb8bec0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|avg(average_rating)|\n",
      "+-------------------+\n",
      "|  3.955161290322582|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#We use regular expressions to isolate the average ratings of the books that start with 'I', and with the AVG function we get their average value\n",
    "avg_rating_I_book = spark.sql(\"SELECT AVG(average_rating) FROM test_books WHERE (title like 'I%' OR title like 'i%')\")\n",
    "avg_rating_I_book.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "a29bc12d-3c78-440b-af9d-c4823ac2e541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+\n",
      "| book_id|               title|\n",
      "+--------+--------------------+\n",
      "|10324691|Naruto (3-in-1 Ed...|\n",
      "+--------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#We use regular expressions to isolate the books that start with the 'N'. We also filter only books that have a paperback format and have a recorded number of pages.\n",
    "#We order the books based on their number of pages in descending order and we keep only the first book's title and book_id using the limit command.\n",
    "Paperback_books = spark.sql(\"SELECT book_id, title FROM test_books WHERE (title like 'N%' OR title like 'n%') \\\n",
    "                            AND format = 'Paperback' AND num_pages != '' ORDER BY CAST(num_pages AS INT) DESC LIMIT 1\")\n",
    "Paperback_books.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf189bc-b77f-4f2e-a6c2-8f54be46ecc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
